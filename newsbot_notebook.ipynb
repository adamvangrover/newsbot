{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NewsBot Interactive Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook allows you to interactively configure and run NewsBot. You can use it to:\n",
    "- Aggregate news from various sources (NewsAPI, CoinGecko, Reuters RSS).\n",
    "- Personalize the news feed based on your topics of interest and financial portfolio.\n",
    "- Analyze sentiment of news articles using a FinBERT model.\n",
    "- Generate comprehensive analysis reports including summaries, critical analysis, and actionable insights.\n",
    "- Perform targeted web searches for specific queries (uses a placeholder API for now).\n",
    "- Monitor news for critical updates over a defined duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use\n",
    "\n",
    "1.  **Execute All Cells:** It's recommended to run all cells initially to ensure all components are loaded. Click `Runtime` -> `Run all` or `Cell` -> `Run All`.\n",
    "2.  **Configure User Preferences & API Keys:**\n",
    "    *   **User Preferences (JSON):** Define your interests. \n",
    "        *   `topics`: A list of topics like `[\"finance\", \"crypto\", \"stocks\", \"commodities\", \"treasuries\", \"forex\"]`.\n",
    "        *   `enable_analysis_reporting`: Set to `true` to get full analysis reports, `false` for just headlines.\n",
    "        *   `alerting_thresholds`: Define `positive_impact` and `negative_impact` scores (e.g., `0.6` and `-0.6`) to trigger alerts (printed in the output area).\n",
    "        *   _Example:_ `{\"topics\": [\"ai\", \"technology\"], \"enable_analysis_reporting\": true, \"alerting_thresholds\": {\"positive_impact\": 0.7, \"negative_impact\": -0.5}}`\n",
    "    *   **NewsAPI Key:** **Required for most news features.** Get a free key from [newsapi.org](https://newsapi.org).\n",
    "    *   **Portfolio (JSON):** Specify your financial holdings to get relevant news. \n",
    "        *   Use keys like `\"stocks\"` and `\"crypto\"` with a list of symbols.\n",
    "        *   _Example:_ `{\"stocks\": [\"MSFT\", \"TSLA\"], \"crypto\": [\"SOL\"]}`\n",
    "    *   **Custom API Sources (JSON - Optional):** Add other news sources if they follow the NewsAPI article structure. \n",
    "        *   _Example:_ `[{\"name\": \"My Custom Tech News\", \"url\": \"https://my.custom.news/api/tech\"}]`\n",
    "    *   **Search API Key (Optional):** For the web search feature (currently uses a placeholder, so no key is strictly needed for mock results).\n",
    "\n",
    "3.  **Configure Bot Behavior:**\n",
    "    *   **Search Query (Optional):** If you want to perform a direct web search instead of news aggregation, enter your query here (e.g., `\"future of renewable energy\"`). This overrides the default news aggregation flow.\n",
    "    *   **Generate Analysis Report:** Check this box if you want a detailed report. If unchecked (and not searching/monitoring), you'll get a list of personalized articles.\n",
    "\n",
    "4.  **Configure News Monitoring (Optional):**\n",
    "    *   **Enable News Monitoring:** Check this to continuously monitor news for critical updates. This overrides the default news aggregation and search query flows.\n",
    "    *   **Duration (minutes):** How long the monitoring should last.\n",
    "    *   **Interval (seconds):** How often to check for new articles during monitoring.\n",
    "\n",
    "5.  **Run NewsBot:** After filling in the fields, click the **\"Run NewsBot\"** button.\n",
    "\n",
    "6.  **View Output:** Results, logs, and reports will appear in the output area below the button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "*   **Package Installation:** When you run the code cells for the first time (especially the NewsBot class definition), the notebook might take a while as it needs to download and install several Python packages if they are not already in your environment. These include:\n",
    "    *   `ipywidgets` (for the interactive UI elements)\n",
    "    *   `transformers` (for NLP models)\n",
    "    *   `torch` (PyTorch, as a backend for transformers)\n",
    "    *   `nltk` (Natural Language Toolkit, for text processing)\n",
    "    *   `feedparser` (for parsing RSS feeds like Reuters)\n",
    "    *   `pycoingecko` (for cryptocurrency data)\n",
    "    *   `semantic-kernel` (though used minimally in this version, good to have for future extensions)\n",
    "    *   `scikit-learn` (for clustering and other ML utilities)\n",
    "    *   _You might need to run `pip install <package_name>` in a separate cell or your terminal if you encounter import errors._\n",
    "\n",
    "*   **NLTK Data Download:** The NewsBot requires the `punkt` tokenizer models from NLTK. If not found, it will attempt to download them automatically when the NewsBot class is initialized or when the `run_newsbot_from_widgets` function is executed. This is a one-time download.\n",
    "\n",
    "*   **Transformer Models Download:** The NewsBot uses pre-trained models for sentiment analysis (FinBERT) and summarization (DistilBART). These models will be downloaded from Hugging Face Hub the first time the NewsBot class is initialized. \n",
    "    *   This can take a significant amount of time (several minutes) and disk space (hundreds of MBs to a few GBs depending on the models).\n",
    "    *   Ensure you have a stable internet connection for these downloads.\n",
    "\n",
    "*   **Kernel Selection:** Ensure you are using a Python 3 kernel in your Jupyter environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "All logs, status messages, personalized news feeds, analysis reports, or search results generated by NewsBot will be displayed in the text area directly below the \"Run NewsBot\" button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "# Define Layouts for better spacing\n",
    "field_layout = widgets.Layout(width='auto', margin='5px 0') # For individual input fields\n",
    "box_layout = widgets.Layout(display='flex', flex_flow='column', align_items='stretch', border='1px solid #ccc', padding='10px', margin_bottom='10px')\n",
    "title_layout = widgets.Layout(margin='0 0 10px 0')\n",
    "\n",
    "# --- User Preferences and API Keys --- (Section 1)\n",
    "display(widgets.HTML(value=\"<h3 style='margin-bottom: 5px;'>User Configuration & API Keys</h3>\", layout=title_layout))\n",
    "user_preferences_widget = widgets.Textarea(\n",
    "    value=json.dumps({'topics': ['finance', 'crypto'], 'enable_analysis_reporting': True, 'alerting_thresholds': {'positive_impact': 0.6, 'negative_impact': -0.6}}),\n",
    "    description='User Preferences (JSON):',\n",
    "    layout=widgets.Layout(width='95%', height='100px', margin='5px 0'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "news_api_key_widget = widgets.Text(\n",
    "    description='NewsAPI Key:', \n",
    "    placeholder='Enter your NewsAPI key',\n",
    "    layout=field_layout,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "portfolio_widget = widgets.Textarea(\n",
    "    value=json.dumps({'stocks': ['AAPL', 'GOOGL'], 'crypto': ['BTC', 'ETH']}),\n",
    "    description='Portfolio (JSON):',\n",
    "    layout=widgets.Layout(width='95%', height='80px', margin='5px 0'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "custom_api_sources_widget = widgets.Textarea(\n",
    "    value=json.dumps([]),\n",
    "    description='Custom API Sources (JSON - Optional):',\n",
    "    layout=widgets.Layout(width='95%', height='80px', margin='5px 0'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "search_api_key_widget = widgets.Text(\n",
    "    description='Search API Key (Optional):', \n",
    "    placeholder='Enter search API key if using web search',\n",
    "    layout=field_layout,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "config_box = widgets.VBox([\n",
    "    user_preferences_widget, \n",
    "    news_api_key_widget, \n",
    "    portfolio_widget, \n",
    "    custom_api_sources_widget, \n",
    "    search_api_key_widget\n",
    "], layout=box_layout)\n",
    "\n",
    "# --- Bot Behavior --- (Section 2)\n",
    "display(widgets.HTML(value=\"<h3 style='margin-bottom: 5px;'>Bot Behavior</h3>\", layout=title_layout))\n",
    "search_query_widget = widgets.Text(\n",
    "    description='Search Query (Optional):', \n",
    "    placeholder='e.g., latest AI advancements',\n",
    "    layout=field_layout,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "generate_report_widget = widgets.Checkbox(\n",
    "    value=True, \n",
    "    description='Generate Analysis Report',\n",
    "    indent=False,\n",
    "    layout=field_layout\n",
    ")\n",
    "behavior_box = widgets.VBox([\n",
    "    search_query_widget, \n",
    "    generate_report_widget\n",
    "], layout=box_layout)\n",
    "\n",
    "# --- News Monitoring --- (Section 3)\n",
    "display(widgets.HTML(value=\"<h3 style='margin-bottom: 5px;'>News Monitoring (Optional)</h3>\", layout=title_layout))\n",
    "monitor_news_widget = widgets.Checkbox(\n",
    "    value=False, \n",
    "    description='Enable News Monitoring',\n",
    "    indent=False,\n",
    "    layout=field_layout\n",
    ")\n",
    "monitor_duration_widget = widgets.IntText(\n",
    "    value=5, \n",
    "    description='Duration (minutes):',\n",
    "    layout=field_layout,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "monitor_interval_widget = widgets.IntText(\n",
    "    value=60, \n",
    "    description='Interval (seconds):',\n",
    "    layout=field_layout,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "monitoring_box = widgets.VBox([\n",
    "    monitor_news_widget, \n",
    "    monitor_duration_widget, \n",
    "    monitor_interval_widget\n",
    "], layout=box_layout)\n",
    "\n",
    "# --- Action Buttons & Output --- (Section 4)\n",
    "display(widgets.HTML(value=\"<h3 style='margin-bottom: 5px;'>Actions & Output</h3>\", layout=title_layout))\n",
    "run_button = widgets.Button(description='Run NewsBot', button_style='success', layout=widgets.Layout(width='auto', margin='10px 0'))\n",
    "output_area = widgets.Output(layout=widgets.Layout(border='1px solid #ccc', padding='10px', min_height='200px', width='95%')) # Min height for visibility\n",
    "\n",
    "# Display sections\n",
    "display(Markdown(\"## NewsBot Configuration Panel\"))\n",
    "display(config_box)\n",
    "display(behavior_box)\n",
    "display(monitoring_box)\n",
    "display(run_button)\n",
    "display(output_area)\n",
    "\n",
    "# The function 'run_newsbot_from_widgets' is defined in the third cell.\n",
    "# After executing that cell, it will be available in the notebook's global scope.\n",
    "run_button.on_click(run_newsbot_from_widgets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "from typing import Dict, Any, Optional, List\n",
    "import feedparser # Added import\n",
    "import time # For parsing published_at if needed\n",
    "from datetime import timezone # For timezone aware datetime objects\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "\n",
    "import torch # Added import\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification # Added import\n",
    "\n",
    "import nltk # Added import for sentence tokenization in summarizer fallback\n",
    "from transformers import AutoModelForSeq2SeqLM # Added import for summarization model\n",
    "\n",
    "class AgentBase:\n",
    "    def __init__(self, config: Dict[str, Any], kernel: Optional[Any] = None):\n",
    "        self.config = config\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def get_skill_schema(self) -> Dict[str, Any]:\n",
    "        return {}\n",
    "\n",
    "    async def receive_message(self, sender_agent: str, message: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        print(f\"AgentBase received message from {sender_agent}: {message}\")\n",
    "        return None\n",
    "\n",
    "# Define the \"NewsBot\" class, now inheriting from AgentBase\n",
    "class NewsBot(AgentBase):\n",
    "    def __init__(self, config: Dict[str, Any], kernel: Optional[Kernel] = None):\n",
    "        \"\"\"\n",
    "        Initializes the NewsBot Agent.\n",
    "        \n",
    "        Args:\n",
    "            config (Dict[str, Any]): Agent configuration.\n",
    "            kernel (Optional[Kernel]): Semantic Kernel instance.\n",
    "        \"\"\"\n",
    "        super().__init__(config, kernel)\n",
    "        \n",
    "        # Extract configurations from self.config (set by AgentBase)\n",
    "        self.user_preferences = self.config.get('user_preferences', {})\n",
    "        self.news_api_key = self.config.get('news_api_key', None)\n",
    "        self.search_api_key = self.config.get('search_api_key', None) # Added search_api_key\n",
    "        self.portfolio = self.config.get('portfolio', {})\n",
    "        self.user_api_sources = self.config.get('user_api_sources', [])\n",
    "        \n",
    "        # Make sure alerting_thresholds are part of user_preferences or self.config directly\n",
    "        # If they are in user_preferences, they will be used from there.\n",
    "        # If they are meant to be a direct part of NewsBot's config (not from user_preferences JSON),\n",
    "        # then it should be: self.alerting_thresholds = self.config.get('alerting_thresholds', {})\n",
    "        # For now, assuming it's within user_preferences as per the widget setup.\n",
    "        # self.alerting_thresholds = self.user_preferences.get('alerting_thresholds', {})\n",
    "        # Let's ensure it's taken from the main config if not in user_preferences\n",
    "        self.alerting_thresholds = self.config.get('alerting_thresholds', self.user_preferences.get('alerting_thresholds', {}))\n",
    "\n",
    "        if not self.news_api_key:\n",
    "            print(\"Warning: news_api_key is not configured for NewsBot.\")\n",
    "        if not self.search_api_key:\n",
    "            print(\"Warning: search_api_key is not configured for NewsBot. Web search will be unavailable.\")\n",
    "\n",
    "        self.cg = CoinGeckoAPI()\n",
    "        self.aggregated_news: List[Dict[str, Any]] = []\n",
    "        self.user_interactions: Dict[str, int] = defaultdict(int)\n",
    "        self.custom_news_sources = self.load_custom_sources()\n",
    "\n",
    "        # Load FinBERT model and tokenizer\n",
    "        self.finbert_tokenizer = None\n",
    "        self.finbert_model = None\n",
    "        self.summarizer_tokenizer = None\n",
    "        self.summarizer_model = None\n",
    "        self.seen_alert_urls = set() # For tracking alerted articles in the current session\n",
    "\n",
    "        # Load FinBERT model and tokenizer\n",
    "        try:\n",
    "            model_name_finbert = \"ProsusAI/finbert\"\n",
    "            self.finbert_tokenizer = AutoTokenizer.from_pretrained(model_name_finbert)\n",
    "            self.finbert_model = AutoModelForSequenceClassification.from_pretrained(model_name_finbert)\n",
    "            print(f\"FinBERT model ({model_name_finbert}) loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading FinBERT model: {e}. Sentiment analysis will be impacted.\")\n",
    "\n",
    "        # Load Summarization model and tokenizer\n",
    "        try:\n",
    "            model_name_summarizer = \"sshleifer/distilbart-cnn-12-6\" # Using a smaller model due to space constraints\n",
    "            self.summarizer_tokenizer = AutoTokenizer.from_pretrained(model_name_summarizer)\n",
    "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_summarizer)\n",
    "            print(f\"Summarization model ({model_name_summarizer}) loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Summarization model: {e}. Summarization will use fallback.\")\n",
    "            # Ensure NLTK's punkt is available for fallback\n",
    "            try:\n",
    "                nltk.data.find('tokenizers/punkt')\n",
    "            except nltk.downloader.DownloadError:\n",
    "                print(\"NLTK 'punkt' not found. Downloading...\")\n",
    "                nltk.download('punkt', quiet=True) # quiet=True to avoid verbose output if already there or successful\n",
    "\n",
    "    def load_custom_sources(self) -> Dict[str, str]:\n",
    "        \"\"\"Load custom news APIs provided by the user.\"\"\"\n",
    "        custom_sources = {}\n",
    "        for source in self.user_api_sources:\n",
    "            custom_sources[source['name']] = source['url']\n",
    "        return custom_sources\n",
    "\n",
    "    def aggregate_news(self) -> List[Dict[str, Any]]: # Added return type hint\n",
    "        \"\"\"\n",
    "        Aggregates news articles from various sources (including custom user sources).\n",
    "        \n",
    "        Returns:\n",
    "            list: Aggregated news articles\n",
    "        \"\"\"\n",
    "        all_news: List[Dict[str, Any]] = [] # Added type hint\n",
    "\n",
    "        # Collect crypto-related news\n",
    "        if 'crypto' in self.user_preferences.get('topics', []): # Safe get\n",
    "            all_news.extend(self.get_crypto_news())\n",
    "\n",
    "        # Collect financial market-related news\n",
    "        if 'finance' in self.user_preferences.get('topics', []): # Safe get\n",
    "            all_news.extend(self.get_finance_news())\n",
    "\n",
    "        # Collect stock market news\n",
    "        if 'stocks' in self.user_preferences.get('topics', []): # Safe get\n",
    "            all_news.extend(self.get_stock_news())\n",
    "\n",
    "        # Collect commodities and treasury news\n",
    "        if 'commodities' in self.user_preferences.get('topics', []): # Safe get\n",
    "            all_news.extend(self.get_commodities_news())\n",
    "\n",
    "        if 'treasuries' in self.user_preferences.get('topics', []): # Safe get\n",
    "            all_news.extend(self.get_treasuries_news())\n",
    "\n",
    "        # Collect FX news\n",
    "        if 'forex' in self.user_preferences.get('topics', []): # Safe get\n",
    "            all_news.extend(self.get_forex_news())\n",
    "\n",
    "        # Add Reuters Business News RSS\n",
    "        all_news.extend(self.get_reuters_business_news_rss())\n",
    "\n",
    "        # Integrate custom sources (user-defined)\n",
    "        for source_name, source_url in self.custom_news_sources.items():\n",
    "            all_news.extend(self.get_custom_news(source_url))\n",
    "\n",
    "        # Filter news based on user's portfolio\n",
    "        filtered_news = self.filter_news_by_portfolio(all_news)\n",
    "\n",
    "        return filtered_news\n",
    "\n",
    "    def get_crypto_news(self) -> List[Dict[str, Any]]: # Added return type hint\n",
    "        \"\"\"Fetch cryptocurrency news using the CoinGeckoAPI.\"\"\"\n",
    "        try:\n",
    "            trending_searches = self.cg.get_trending_searches()\n",
    "            news_items = []\n",
    "            if isinstance(trending_searches, dict) and 'coins' in trending_searches:\n",
    "                for coin_info in trending_searches['coins']:\n",
    "                    item = coin_info.get('item', {})\n",
    "                    news_items.append({\n",
    "                        'title': f\"Trending: {item.get('name', 'Unknown Coin')} ({item.get('symbol', '')})\",\n",
    "                        'description': f\"Market Cap Rank: {item.get('market_cap_rank', 'N/A')}, Score: {item.get('score', 'N/A')}\",\n",
    "                        'source': {'name': 'CoinGecko Trending'},\n",
    "                        'url': f\"https://www.coingecko.com/en/coins/{item.get('id', '')}\" if item.get('id') else None\n",
    "                    })\n",
    "            return news_items\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching crypto news from CoinGecko: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_finance_news(self) -> List[Dict[str, Any]]:\n",
    "        if not self.news_api_key: return []\n",
    "        url = \"https://newsapi.org/v2/everything\"\n",
    "        params = {'q': 'finance', 'apiKey': self.news_api_key, 'language': 'en', 'sortBy': 'relevancy'}\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('articles', [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching finance news from NewsAPI: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_stock_news(self) -> List[Dict[str, Any]]:\n",
    "        if not self.news_api_key: return []\n",
    "        url = \"https://newsapi.org/v2/everything\"\n",
    "        params = {'q': 'stocks', 'apiKey': self.news_api_key, 'language': 'en', 'sortBy': 'relevancy'}\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('articles', [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching stock news from NewsAPI: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_commodities_news(self) -> List[Dict[str, Any]]:\n",
    "        if not self.news_api_key: return []\n",
    "        url = \"https://newsapi.org/v2/everything\"\n",
    "        params = {'q': 'commodities', 'apiKey': self.news_api_key, 'language': 'en', 'sortBy': 'relevancy'}\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('articles', [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching commodities news from NewsAPI: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_treasuries_news(self) -> List[Dict[str, Any]]:\n",
    "        if not self.news_api_key: return []\n",
    "        url = \"https://newsapi.org/v2/everything\"\n",
    "        params = {'q': 'treasury bonds', 'apiKey': self.news_api_key, 'language': 'en', 'sortBy': 'relevancy'}\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('articles', [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching treasuries news from NewsAPI: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_forex_news(self) -> List[Dict[str, Any]]:\n",
    "        if not self.news_api_key: return []\n",
    "        url = \"https://newsapi.org/v2/everything\"\n",
    "        params = {'q': 'forex', 'apiKey': self.news_api_key, 'language': 'en', 'sortBy': 'relevancy'}\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('articles', [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching forex news from NewsAPI: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_custom_news(self, api_url: str) -> List[Dict[str, Any]]:\n",
    "        try:\n",
    "            response = requests.get(api_url)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('articles', [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching custom news from {api_url}: {e}\")\n",
    "            return []\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {api_url}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_reuters_business_news_rss(self) -> List[Dict[str, Any]]:\n",
    "        feed_url = \"http://feeds.reuters.com/reuters/businessNews\"\n",
    "        news_items: List[Dict[str, Any]] = []\n",
    "        try:\n",
    "            feed = feedparser.parse(feed_url)\n",
    "            for entry in feed.entries:\n",
    "                published_at = None\n",
    "                if hasattr(entry, 'published_parsed') and entry.published_parsed:\n",
    "                    dt_object = datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=timezone.utc)\n",
    "                    published_at = dt_object.isoformat()\n",
    "                elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:\n",
    "                    dt_object = datetime.fromtimestamp(time.mktime(entry.updated_parsed), tz=timezone.utc)\n",
    "                    published_at = dt_object.isoformat()\n",
    "                news_items.append({\n",
    "                    'title': entry.title if hasattr(entry, 'title') else 'No Title',\n",
    "                    'description': entry.summary if hasattr(entry, 'summary') else 'No Description',\n",
    "                    'link': entry.link if hasattr(entry, 'link') else '',\n",
    "                    'published_at': published_at,\n",
    "                    'source': {'name': 'Reuters Business News'}\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching or parsing Reuters RSS feed: {e}\")\n",
    "        return news_items\n",
    "\n",
    "    def filter_news_by_portfolio(self, news_articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        filtered_news: List[Dict[str, Any]] = []\n",
    "        symbols_to_check = []\n",
    "        if isinstance(self.portfolio, dict):\n",
    "            for key in self.portfolio: # Iterate through keys like 'stocks', 'crypto'\n",
    "                if isinstance(self.portfolio[key], list):\n",
    "                    symbols_to_check.extend(self.portfolio[key])\n",
    "        elif isinstance(self.portfolio, list): # Support flat list of symbols directly\n",
    "            symbols_to_check.extend(self.portfolio)\n",
    "\n",
    "        for article in news_articles:\n",
    "            title_lower = article.get('title', '').lower() # Ensure lowercase for consistent matching\n",
    "            description_lower = article.get('description', '').lower() # Ensure lowercase\n",
    "            if not title_lower and not description_lower: # Skip if no content to check\n",
    "                continue\n",
    "            \n",
    "            for symbol_obj in symbols_to_check:\n",
    "                symbol = str(symbol_obj).lower() # Ensure symbol is lowercase string\n",
    "                if symbol in title_lower or symbol in description_lower:\n",
    "                    filtered_news.append(article)\n",
    "                    break # Found a match for this article, move to next article\n",
    "        return filtered_news\n",
    "\n",
    "    def analyze_sentiment(self, article: Dict[str, Any]) -> float:\n",
    "        text = article.get('title', '') + \" \" + article.get('description', '')\n",
    "        if not text.strip(): return 0.0\n",
    "        if not self.finbert_tokenizer or not self.finbert_model: return 0.0\n",
    "        try:\n",
    "            inputs = self.finbert_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "            with torch.no_grad(): outputs = self.finbert_model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=-1)\n",
    "            positive_prob = probs[0][0].item()\n",
    "            negative_prob = probs[0][1].item()\n",
    "            # neutral_prob = probs[0][2].item() # Not strictly needed for pos/neg determination\n",
    "            if positive_prob > negative_prob: return 1.0\n",
    "            elif negative_prob > positive_prob: return -1.0\n",
    "            return 0.0\n",
    "        except Exception as e:\n",
    "            print(f\"Error during FinBERT sentiment analysis: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "    def analyze_impact(self, article: Dict[str, Any]) -> float:\n",
    "        sentiment_score = self.analyze_sentiment(article)\n",
    "        portfolio_relevance = 0\n",
    "        title = article.get('title', '') \n",
    "        description = article.get('description', '')\n",
    "\n",
    "        symbols_to_check = []\n",
    "        if isinstance(self.portfolio, dict):\n",
    "            for key in self.portfolio:\n",
    "                if isinstance(self.portfolio[key], list):\n",
    "                    symbols_to_check.extend(self.portfolio[key])\n",
    "        elif isinstance(self.portfolio, list):\n",
    "            symbols_to_check.extend(self.portfolio)\n",
    "\n",
    "        title_lower = title.lower() # Ensure lowercase for consistent matching\n",
    "        description_lower = description.lower() # Ensure lowercase\n",
    "\n",
    "        for symbol_obj in symbols_to_check:\n",
    "            symbol = str(symbol_obj).lower()\n",
    "            if symbol in title_lower or symbol in description_lower:\n",
    "                portfolio_relevance += 1\n",
    "                # If only one match per article is desired to count for relevance, break here.\n",
    "                # Current: counts all symbol occurrences across categories for relevance.\n",
    "        return sentiment_score * (1 + portfolio_relevance)\n",
    "\n",
    "    def personalize_feed(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        personalized_articles: List[Dict[str, Any]] = []\n",
    "        for article in articles:\n",
    "            article['impact_score'] = self.analyze_impact(article)\n",
    "            article['sentiment_score'] = self.analyze_sentiment(article)\n",
    "            personalized_articles.append(article)\n",
    "        personalized_articles.sort(key=lambda x: x.get('impact_score', 0), reverse=True)\n",
    "        return personalized_articles\n",
    "\n",
    "    def send_alerts(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        # Use self.alerting_thresholds which should be set in __init__\n",
    "        positive_threshold = self.alerting_thresholds.get('positive_impact', 0.5)\n",
    "        negative_threshold = self.alerting_thresholds.get('negative_impact', -0.5)\n",
    "        alert_worthy_articles_in_batch = []\n",
    "        for article in articles:\n",
    "            impact_score = article.get('impact_score', 0)\n",
    "            title = article.get('title', 'No Title')\n",
    "            article_url = article.get('link', article.get('url'))\n",
    "            is_alert_worthy = False\n",
    "            alert_type = \"\"\n",
    "            if impact_score > positive_threshold: is_alert_worthy, alert_type = True, \"Impactful news\"\n",
    "            elif impact_score < negative_threshold: is_alert_worthy, alert_type = True, \"Negative news\"\n",
    "            if is_alert_worthy:\n",
    "                alert_worthy_articles_in_batch.append(article)\n",
    "                unique_id = article_url if (article_url and isinstance(article_url, str) and article_url.strip()) else title\n",
    "                if unique_id not in self.seen_alert_urls:\n",
    "                    print(f\"ALERT: {alert_type} - {title}\\nScore: {impact_score:.2f}\\nLink: {article_url or 'N/A'}\")\n",
    "                    self.seen_alert_urls.add(unique_id)\n",
    "        return alert_worthy_articles_in_batch\n",
    "\n",
    "    async def execute(self, *args: Any, **kwargs: Any) -> Dict[str, Any]:\n",
    "        print(f\"NewsBot executing cycle at {datetime.now(timezone.utc).isoformat()}\")\n",
    "        news_articles = self.aggregate_news()\n",
    "        personalized_feed = self.personalize_feed(news_articles)\n",
    "        self.send_alerts(personalized_feed)\n",
    "        self.aggregated_news = personalized_feed\n",
    "        analysis_report = None\n",
    "        if self.user_preferences.get('enable_analysis_reporting', True) and personalized_feed:\n",
    "            summary = await self.summarize_articles(personalized_feed[:5])\n",
    "            critical_analysis = self.perform_critical_analysis(personalized_feed[:10])\n",
    "            actionable_insights = self.draw_conclusions(critical_analysis)\n",
    "            analysis_report = self.generate_report(personalized_feed[:5], summary, critical_analysis, actionable_insights)\n",
    "        return {'personalized_feed': personalized_feed, 'analysis_report': analysis_report}\n",
    "\n",
    "    async def monitor_for_critical_news(self, duration_minutes: int = 5, interval_seconds: int = 60) -> List[Dict[str, Any]]:\n",
    "        print(f\"Starting news monitoring for {duration_minutes} minutes, checking every {interval_seconds} seconds.\")\n",
    "        all_critical_news_session: Dict[str, Dict[str, Any]] = {}\n",
    "        loop = asyncio.get_event_loop()\n",
    "        end_time = loop.time() + duration_minutes * 60\n",
    "        positive_threshold = self.alerting_thresholds.get('positive_impact', 0.5)\n",
    "        negative_threshold = self.alerting_thresholds.get('negative_impact', -0.5)\n",
    "\n",
    "        while loop.time() < end_time:\n",
    "            print(f\"Monitoring... running news check at {datetime.now(timezone.utc).isoformat()}\")\n",
    "            results_dict = await self.execute()\n",
    "            if results_dict.get('personalized_feed'):\n",
    "                for article in results_dict['personalized_feed']:\n",
    "                    impact_score = article.get('impact_score', 0.0)\n",
    "                    if impact_score > positive_threshold or impact_score < negative_threshold:\n",
    "                        article_url = article.get('link', article.get('url'))\n",
    "                        unique_key = article_url if (article_url and isinstance(article_url, str) and article_url.strip()) else article.get('title', str(random.random()))\n",
    "                        if unique_key not in all_critical_news_session:\n",
    "                            all_critical_news_session[unique_key] = article\n",
    "            remaining_time = end_time - loop.time()\n",
    "            if remaining_time > interval_seconds: await asyncio.sleep(interval_seconds)\n",
    "            elif remaining_time > 0: await asyncio.sleep(remaining_time)\n",
    "            else: break\n",
    "        print(\"Monitoring finished.\")\n",
    "        return list(all_critical_news_session.values())\n",
    "\n",
    "    async def summarize_articles(self, articles: List[Dict[str, Any]]) -> str:\n",
    "        if not articles: return \"No articles for summarization.\"\n",
    "        if self.summarizer_tokenizer and self.summarizer_model:\n",
    "            try:\n",
    "                text_to_summarize = \" \".join([article.get('description', article.get('title', '')) for article in articles if article.get('description', article.get('title', ''))])\n",
    "                if not text_to_summarize.strip(): return \"No content for summarization.\"\n",
    "                inputs = self.summarizer_tokenizer(text_to_summarize, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"longest\")\n",
    "                summary_ids = self.summarizer_model.generate(inputs.input_ids, num_beams=4, max_length=150, early_stopping=True)\n",
    "                return self.summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during model-based summarization: {e}. Fallback.\")\n",
    "        print(\"Using fallback summarization.\")\n",
    "        summary_parts = []\n",
    "        for article in articles[:3]:\n",
    "            text = article.get('description', article.get('title', ''))\n",
    "            if text:\n",
    "                try: nltk.data.find('tokenizers/punkt')\n",
    "                except nltk.downloader.DownloadError: return \"Summarization fallback failed: NLTK 'punkt' missing.\"\n",
    "                sentences = nltk.sent_tokenize(text)\n",
    "                if sentences: summary_parts.append(sentences[0])\n",
    "        return \" \".join(summary_parts) if summary_parts else \"No content for fallback summary.\"\n",
    "\n",
    "    def perform_critical_analysis(self, articles: List[Dict[str, Any]]) -> str:\n",
    "        if not articles: return \"No articles for critical analysis.\"\n",
    "        analysis_points, conflicting_sentiments = [], {}\n",
    "        portfolio_symbols = [str(s).lower() for s in self.portfolio.get('stocks', []) + self.portfolio.get('crypto', [])]\n",
    "        for article in articles:\n",
    "            content = (article.get('title', '') + \" \" + article.get('description', '')).lower()\n",
    "            sentiment = article.get('sentiment_score', 0.0)\n",
    "            for symbol in portfolio_symbols:\n",
    "                if symbol in content:\n",
    "                    conflicting_sentiments.setdefault(symbol, []).append(sentiment)\n",
    "        for symbol, sentiments in conflicting_sentiments.items():\n",
    "            if any(s > 0.5 for s in sentiments) and any(s < -0.5 for s in sentiments):\n",
    "                analysis_points.append(f\"Conflicting sentiment for {symbol.upper()}.\")\n",
    "        risk_keywords = [\"warning\", \"concern\", \"risk\", \"volatile\", \"downturn\", \"bubble\"]\n",
    "        opportunity_keywords = [\"breakthrough\", \"opportunity\", \"growth\", \"bullish\", \"upward\", \"promising\"]\n",
    "        found_risks, found_opportunities = set(), set()\n",
    "        for article in articles:\n",
    "            content = (article.get('title', '') + \" \" + article.get('description', '')).lower()\n",
    "            for r_keyword in risk_keywords: \n",
    "                if r_keyword in content: found_risks.add(r_keyword)\n",
    "            for o_keyword in opportunity_keywords:\n",
    "                if o_keyword in content: found_opportunities.add(o_keyword)\n",
    "        if found_risks: analysis_points.append(f\"Risks: {', '.join(found_risks)}.\")\n",
    "        if found_opportunities: analysis_points.append(f\"Opportunities: {', '.join(found_opportunities)}.\")\n",
    "        return \"\\n- \".join(analysis_points) if analysis_points else \"No specific critical points identified.\"\n",
    "\n",
    "    def draw_conclusions(self, critical_analysis_text: str) -> str:\n",
    "        insights = []\n",
    "        if not critical_analysis_text or \"No specific critical points\" in critical_analysis_text: return \"No specific insights.\"\n",
    "        if \"conflicting sentiment\" in critical_analysis_text.lower(): insights.append(\"Review items with conflicting sentiment.\")\n",
    "        if \"Risks:\" in critical_analysis_text: insights.append(\"Monitor for identified risks.\")\n",
    "        if \"Opportunities:\" in critical_analysis_text: insights.append(\"Explore highlighted opportunities.\")\n",
    "        return \"\\n- \".join(insights) if insights else \"General market awareness recommended.\"\n",
    "\n",
    "    def generate_report(self, articles: List[Dict[str, Any]], summary: str, critical_analysis: str, actionable_insights: str) -> str:\n",
    "        report_parts = [\"--- News Analysis Report ---\", f\"\\nOverall Summary:\\n{summary}\", f\"\\nCritical Analysis:\\n- {critical_analysis}\", f\"\\nActionable Insights:\\n- {actionable_insights}\", \"\\nSources (Top Articles Used):\"]\n",
    "        for i, article in enumerate(articles[:5]):\n",
    "            report_parts.append(f\"  {i+1}. {article.get('title', 'N/A')}\\n     Link: {article.get('link', article.get('url', 'N/A'))}\\n     Sentiment: {article.get('sentiment_score', 0.0):.2f}, Impact: {article.get('impact_score', 0.0):.2f}\")\n",
    "        report_parts.append(\"\\n--- End of Report ---\")\n",
    "        return \"\\n\".join(report_parts)\n",
    "\n",
    "    def get_skill_schema(self) -> Dict[str, Any]:\n",
    "        schema = super().get_skill_schema()\n",
    "        schema[\"description\"] = self.config.get(\"description\", \"NewsBot: Monitors, aggregates, personalizes news.\")\n",
    "        schema[\"skills\"] = [\n",
    "            {\"name\": \"get_latest_news\", \"description\": \"Get latest personalized news.\", \"parameters\": []},\n",
    "            {\"name\": \"get_news_for_topic\", \"description\": \"Get news for a topic.\", \"parameters\": [{\"name\": \"topic\", \"type\": \"string\", \"description\": \"Topic\"}]},\n",
    "            {\"name\": \"web_search\", \"description\": \"Web search for query.\", \"parameters\": [{\"name\": \"query\", \"type\": \"string\", \"description\": \"Search query.\"}]},\n",
    "            {\"name\": \"generate_news_analysis_report\", \"description\": \"Generate news analysis report.\", \"parameters\": []},\n",
    "            {\"name\": \"start_news_monitoring\", \"description\": \"Start news monitoring.\", \"parameters\": [\n",
    "                {\"name\": \"duration_minutes\", \"type\": \"integer\", \"description\": \"Duration (minutes)\", \"optional\": True, \"default\": 5},\n",
    "                {\"name\": \"interval_seconds\", \"type\": \"integer\", \"description\": \"Interval (seconds)\", \"optional\": True, \"default\": 60}\n",
    "            ]}\n",
    "        ]\n",
    "        return schema\n",
    "\n",
    "    async def search_web(self, query: str) -> List[Dict[str, Any]]:\n",
    "        if not self.search_api_key: print(\"Warning: Search API key missing.\"); return []\n",
    "        print(f\"INFO: Web search for: \\\"{query}\\\" (placeholder).\" )\n",
    "        current_time_iso = datetime.now(timezone.utc).isoformat()\n",
    "        return [\n",
    "            {'title': f\"Mock Result 1 for '{query}'\", 'link': f\"http://example.com/search?q={query.replace(' ', '+')}&r=1\", 'description': f\"Desc 1 for '{query}'.\", 'published_at': current_time_iso, 'source': {'name': 'Web Search'}},\n",
    "            {'title': f\"Mock Result 2 for '{query}'\", 'link': f\"http://example.com/search?q={query.replace(' ', '+')}&r=2\", 'description': f\"Desc 2 for '{query}'.\", 'published_at': current_time_iso, 'source': {'name': 'Web Search'}}\n",
    "        ]\n",
    "\n",
    "    async def receive_message(self, sender_agent: str, message: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        print(f\"NewsBot received from {sender_agent}: {message}\")\n",
    "        action = message.get(\"action\")\n",
    "        if action == \"get_news_for_topic\":\n",
    "            topic = message.get(\"topic\")\n",
    "            if topic:\n",
    "                original_topics = self.user_preferences.get('topics', [])\n",
    "                self.user_preferences['topics'] = [topic]\n",
    "                news_articles = self.aggregate_news()\n",
    "                personalized_feed = self.personalize_feed(news_articles)\n",
    "                self.user_preferences['topics'] = original_topics\n",
    "                return {\"status\": \"success\", \"articles\": personalized_feed[:10]}\n",
    "            return {\"status\": \"error\", \"message\": \"Topic not provided\"}\n",
    "        return await super().receive_message(sender_agent, message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from typing import Any # For load_json_arg type hint\n",
    "\n",
    "def load_json_arg(json_string: str, arg_name: str, current_output_area: widgets.Output) -> Any:\n",
    "    if not json_string:\n",
    "        # Allow empty JSON strings for optional fields, interpret as empty dict/list or None\n",
    "        if arg_name in [\"Custom API Sources (JSON - Optional)\"]:\n",
    "             return [] # Default to empty list for custom sources\n",
    "        return None \n",
    "    try:\n",
    "        return json.loads(json_string)\n",
    "    except json.JSONDecodeError:\n",
    "        with current_output_area:\n",
    "            print(f\"Error: Invalid JSON for {arg_name}. Content: {json_string}\")\n",
    "        raise ValueError(f\"Invalid JSON for {arg_name}: {json_string}\")\n",
    "    except Exception as e:\n",
    "        with current_output_area:\n",
    "            print(f\"An unexpected error occurred while loading {arg_name}: {e}\")\n",
    "        raise ValueError(f\"Error loading {arg_name}: {e}\")\n",
    "\n",
    "async def run_newsbot_async_operations(news_bot_instance, current_output_area):\n",
    "    \"\"\"Handles the asynchronous operations of NewsBot and prints to the output area.\"\"\"\n",
    "    with current_output_area:\n",
    "        if monitor_news_widget.value:\n",
    "            print(f\"\\n--- Starting News Monitoring (Duration: {monitor_duration_widget.value}m, Interval: {monitor_interval_widget.value}s) ---\")\n",
    "            critical_articles_found = await news_bot_instance.monitor_for_critical_news(\n",
    "                duration_minutes=monitor_duration_widget.value,\n",
    "                interval_seconds=monitor_interval_widget.value\n",
    "            )\n",
    "            print(\"\\n--- All Unique Critical Articles Found During Monitoring Session ---\")\n",
    "            if critical_articles_found:\n",
    "                for i, article_item in enumerate(critical_articles_found):\n",
    "                    print(f\"\\nCritical Article {i+1}:\")\n",
    "                    print(f\"  Title: {article_item.get('title', 'N/A')}\")\n",
    "                    print(f\"  Link: {article_item.get('link', article_item.get('url', 'N/A'))}\")\n",
    "                    print(f\"  Source: {article_item.get('source', {}).get('name', 'N/A')}\")\n",
    "                    print(f\"  Published At: {article_item.get('published_at', 'N/A')}\")\n",
    "                    sentiment_score = article_item.get('sentiment_score', 0.0)\n",
    "                    impact_score = article_item.get('impact_score', 0.0)\n",
    "                    print(f\"  Sentiment Score: {float(sentiment_score):.2f}\")\n",
    "                    print(f\"  Impact Score: {float(impact_score):.2f}\")\n",
    "            else:\n",
    "                print(\"No new critical articles identified during the monitoring session.\")\n",
    "        elif search_query_widget.value and search_query_widget.value.strip():\n",
    "            print(f\"\\n--- Performing Web Search for: \\\"{search_query_widget.value}\\\" ---\")\n",
    "            search_results = await news_bot_instance.search_web(search_query_widget.value)\n",
    "            if search_results:\n",
    "                for i, article_res in enumerate(search_results):\n",
    "                    print(f\"\\nSearch Result {i+1}:\")\n",
    "                    print(f\"  Title: {article_res.get('title', 'N/A')}\")\n",
    "                    print(f\"  Link: {article_res.get('link', 'N/A')}\")\n",
    "                    print(f\"  Source: {article_res.get('source', {}).get('name', 'N/A')}\")\n",
    "                    print(f\"  Published At: {article_res.get('published_at', 'N/A')}\")\n",
    "                    if article_res.get('description'):\n",
    "                        print(f\"  Description: {article_res.get('description')[:150]}...\")\n",
    "            else:\n",
    "                print(\"No search results returned or search_api_key not provided.\")\n",
    "        else:\n",
    "            run_mode_message = \"\\n--- Running Full NewsBot Aggregation & Personalization\"\n",
    "            if generate_report_widget.value:\n",
    "                run_mode_message += \" & Reporting\"\n",
    "            run_mode_message += \" ---\"\n",
    "            print(run_mode_message)\n",
    "            results = await news_bot_instance.execute()\n",
    "            personalized_feed_result = results.get('personalized_feed')\n",
    "            analysis_report_result = results.get('analysis_report')\n",
    "\n",
    "            if generate_report_widget.value:\n",
    "                if analysis_report_result:\n",
    "                    print(\"\\n--- Analysis Report ---\")\n",
    "                    print(analysis_report_result)\n",
    "                else:\n",
    "                    print(\"\\nNo analysis report was generated (e.g., no articles to analyze).\")\n",
    "            else:\n",
    "                print(\"\\n--- Personalized News Feed (Top 10 Articles) ---\")\n",
    "                if personalized_feed_result:\n",
    "                    for i, article_item in enumerate(personalized_feed_result[:10]):\n",
    "                        print(f\"\\nArticle {i+1}:\")\n",
    "                        print(f\"  Title: {article_item.get('title', 'N/A')}\")\n",
    "                        print(f\"  Link: {article_item.get('link', article_item.get('url', 'N/A'))}\")\n",
    "                        print(f\"  Source: {article_item.get('source', {}).get('name', 'N/A')}\")\n",
    "                        print(f\"  Published At: {article_item.get('published_at', 'N/A')}\")\n",
    "                        sentiment_score = article_item.get('sentiment_score', 0.0)\n",
    "                        impact_score = article_item.get('impact_score', 0.0)\n",
    "                        print(f\"  Sentiment Score: {float(sentiment_score):.2f}\")\n",
    "                        print(f\"  Impact Score: {float(impact_score):.2f}\")\n",
    "                        if article_item.get('description'):\n",
    "                            print(f\"  Description: {article_item.get('description')[:150]}...\")\n",
    "                else:\n",
    "                    print(\"No news articles processed or returned in personalized feed.\")\n",
    "        print(\"\\nNewsBot operations finished.\")\n",
    "\n",
    "def run_newsbot_from_widgets(b): # 'b' is the button event, not used directly here\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print(\"Processing... please wait.\")\n",
    "        try:\n",
    "            # NLTK check (optional but good for UX)\n",
    "            try:\n",
    "                nltk.data.find('tokenizers/punkt')\n",
    "            except nltk.downloader.DownloadError:\n",
    "                print(\"NLTK 'punkt' not found. Downloading... This might take a moment.\")\n",
    "                nltk.download('punkt', quiet=True)\n",
    "                print(\"NLTK 'punkt' downloaded.\")\n",
    "            \n",
    "            user_prefs_data = load_json_arg(user_preferences_widget.value, \"User Preferences\", output_area)\n",
    "            portfolio_data = load_json_arg(portfolio_widget.value, \"Portfolio\", output_area)\n",
    "            custom_sources_data = load_json_arg(custom_api_sources_widget.value, \"Custom API Sources (JSON - Optional)\", output_area)\n",
    "            if custom_sources_data is None: custom_sources_data = [] # Default if empty or error\n",
    "\n",
    "            # Ensure alerting_thresholds are correctly sourced\n",
    "            # Default to empty dict if not in user_prefs_data\n",
    "            alert_thresholds = user_prefs_data.get('alerting_thresholds', {})\n",
    "\n",
    "            agent_config = {\n",
    "                \"persona\": \"Interactive NewsBot via Notebook\",\n",
    "                \"description\": \"NewsBot running from Jupyter notebook widgets.\",\n",
    "                \"expertise\": [\"news aggregation\", \"event detection\", \"information filtering\", \"sentiment analysis\", \"web search\"],\n",
    "                \"user_preferences\": user_prefs_data,\n",
    "                \"news_api_key\": news_api_key_widget.value if news_api_key_widget.value else None,\n",
    "                \"search_api_key\": search_api_key_widget.value if search_api_key_widget.value else None,\n",
    "                \"portfolio\": portfolio_data,\n",
    "                \"user_api_sources\": custom_sources_data,\n",
    "                \"alerting_thresholds\": alert_thresholds, # Sourced from user_prefs_data or default\n",
    "                # Ensure enable_analysis_reporting is part of user_preferences, or set directly\n",
    "                \"enable_analysis_reporting\": user_prefs_data.get('enable_analysis_reporting', generate_report_widget.value) \n",
    "            }\n",
    "\n",
    "            # Instantiate NewsBot with the new config\n",
    "            # All print statements from NewsBot's __init__ will also go to output_area\n",
    "            news_bot_instance = NewsBot(config=agent_config, kernel=None) \n",
    "            \n",
    "            # Run the asynchronous operations\n",
    "            # Need to get or create an event loop for asyncio.run in some environments\n",
    "            try:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                if loop.is_closed():\n",
    "                    loop = asyncio.new_event_loop()\n",
    "                    asyncio.set_event_loop(loop)\n",
    "                loop.run_until_complete(run_newsbot_async_operations(news_bot_instance, output_area))\n",
    "            except RuntimeError as e:\n",
    "                 if \"cannot be called from a running event loop\" in str(e):\n",
    "                    # This handles cases where the notebook is already running an event loop (e.g. voila, new ipykernel versions)\n",
    "                    print(\"Detected running event loop. Creating task for async operations.\")\n",
    "                    asyncio.create_task(run_newsbot_async_operations(news_bot_instance, output_area))\n",
    "                    print(\"Async task created. Output will appear below once operations complete.\")\n",
    "                 else:\n",
    "                    raise e # Re-raise other RuntimeErrors\n",
    "\n",
    "        except ValueError as ve:\n",
    "            # JSON parsing errors or other ValueErrors handled by load_json_arg will be caught here\n",
    "            # Error message already printed by load_json_arg or during agent_config construction\n",
    "            print(f\"Configuration Error: {ve}. Please check the input fields.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            import traceback\n",
    "            print(traceback.format_exc()) # Print full traceback for debugging\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

[end of newsbot_notebook.ipynb]
